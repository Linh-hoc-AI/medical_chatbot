{"cells":[{"cell_type":"code","execution_count":40,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-11T09:07:18.008960Z","iopub.status.busy":"2024-03-11T09:07:18.008546Z","iopub.status.idle":"2024-03-11T09:07:18.017282Z","shell.execute_reply":"2024-03-11T09:07:18.016368Z","shell.execute_reply.started":"2024-03-11T09:07:18.008928Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","import pandas as pd\n","from datasets import load_dataset\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","import os\n","target_path = '/your_path'\n","for dirname, _, filenames in os.walk(target_path):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:18.019252Z","iopub.status.busy":"2024-03-11T09:07:18.018972Z","iopub.status.idle":"2024-03-11T09:07:18.033793Z","shell.execute_reply":"2024-03-11T09:07:18.032982Z","shell.execute_reply.started":"2024-03-11T09:07:18.019229Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available.\n"]}],"source":["# Check device, nếu GPU sẵn sàng thì sẽ dùng, không thì dùng CPU\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU is not available. Switching to CPU.\")"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:18.035447Z","iopub.status.busy":"2024-03-11T09:07:18.035081Z","iopub.status.idle":"2024-03-11T09:07:18.746524Z","shell.execute_reply":"2024-03-11T09:07:18.745611Z","shell.execute_reply.started":"2024-03-11T09:07:18.035416Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25981cd316ed4717b5a1e2871ac73cc2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load data lên\n","\n","load_dataset  = load_dataset(\"hungnm/vietnamese-medical-qa\")\n","tokenizer = get_tokenizer(None, language='vi')\n","samples = 100\n","\n","class TextDataset(Dataset):\n","      def __init__(self, input_x, input_y):\n","          self.input_x = input_x\n","          self.input_y = input_y\n","\n","      def __len__(self):\n","            return len(self.input_x+self.input_y)\n","\n","      def __getitem__(self, idx):\n","            input_x_i = self.input_x[idx]\n","            input_y_i = self.input_y[idx]\n","            return {\"text_input\": input_x_i, \"text_output\": input_y_i}\n","\n","def preprocess(load_dataset):\n","  question = load_dataset['train']['question'][:samples]\n","  answer = load_dataset['train']['answer'][:samples]\n","  return question, answer\n","\n","# Tạo dataset và tokenize text\n","\n","dataset = TextDataset(*preprocess(load_dataset))\n","tokenized_input = []\n","tokenized_output = []\n","\n","for text in iter(dataset):\n","  tokens_text_input = tokenizer(text['text_input'])\n","  tokenized_input.append(tokens_text_input)\n","\n","for label in iter(dataset):\n","  tokens_text_output = tokenizer(text['text_output'])\n","  tokenized_output.append(tokens_text_output)\n","\n","tokenized = tokenized_input + tokenized_output\n","\n","# Tạo vocab\n","\n","vocab = build_vocab_from_iterator(iter(tokenized))\n","index_to_word = vocab.get_itos()\n","\n","\n","# Tính toán chiều dài tối đa của các vector\n","max_length = max(len(tokens) for tokens in tokenized)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:18.748058Z","iopub.status.busy":"2024-03-11T09:07:18.747739Z","iopub.status.idle":"2024-03-11T09:07:18.757250Z","shell.execute_reply":"2024-03-11T09:07:18.756461Z","shell.execute_reply.started":"2024-03-11T09:07:18.748031Z"},"trusted":true},"outputs":[],"source":["# Định nghĩa các hàm chuyển đổi\n","\n","def tokenize_input_to_matrix(tokenized_input, vocab_length, max_length):\n","    batch_size = len(tokenized_input)\n","    input_matrix = torch.zeros((batch_size, max_length, vocab_length), dtype=torch.long)\n","    for i, sentence in enumerate(tokenized_input):\n","        for j, token in enumerate(sentence):\n","            if j >= max_length:\n","                break\n","            input_matrix[i, j, vocab([token])[0]] = vocab([token])[0]\n","    return torch.tensor(input_matrix, dtype=torch.long)\n","\n","def tokenize_ques_input_to_matrix(sentence, vocab_length, max_length):\n","    input_matrix = torch.zeros((1, max_length, vocab_length), dtype=torch.long)\n","    for i, token in enumerate(sentence):\n","        if i >= max_length:\n","            break\n","        input_matrix[0, i, vocab([token])[0]] = vocab([token])[0]\n","    return torch.tensor(input_matrix, dtype=torch.long)\n","\n","def vector_to_text(output_vectors, vocabulary):\n","    text = []\n","    # Lấy chỉ mục của từ có xác suất cao nhất\n","    for output_vector in output_vectors:\n","        predicted_index = torch.argmax(output_vector[0]).item()\n","        # Tìm từ tương ứng trong từ điển\n","        predicted_word = index_to_word[predicted_index]\n","        text.append(predicted_word)\n","\n","    return \" \".join(text)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:18.760223Z","iopub.status.busy":"2024-03-11T09:07:18.759929Z","iopub.status.idle":"2024-03-11T09:07:19.217322Z","shell.execute_reply":"2024-03-11T09:07:19.216501Z","shell.execute_reply.started":"2024-03-11T09:07:18.760199Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/620528770.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(input_matrix, dtype=torch.long)\n"]}],"source":["# Tạo vector x_input cho mỗi câu trong tập dữ liệu đã được padding\n","x_input_vectors = tokenize_input_to_matrix(tokenized_input, len(vocab), max_length).to(device)\n","# Tạo vector y_input cho mỗi câu trong tập dữ liệu đã được padding\n","y_input_vectors = tokenize_input_to_matrix(tokenized_output, len(vocab), max_length).to(device)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:19.218991Z","iopub.status.busy":"2024-03-11T09:07:19.218661Z","iopub.status.idle":"2024-03-11T09:07:19.236726Z","shell.execute_reply":"2024-03-11T09:07:19.235774Z","shell.execute_reply.started":"2024-03-11T09:07:19.218965Z"},"trusted":true},"outputs":[],"source":["# Định nghĩa các siêu tham số và kiến trúc model\n","\n","vocab_size = len(vocab)  # Số lượng từ trong từ vựng\n","d_model = 512  # Kích thước vector ẩn cho mỗi từ\n","num_heads = 8  # Số lượng head trong multi-head attention\n","num_layers = 6  # Số lượng layer trong encoder\n","dim_feedforward = 1024  # Kích thước của mạng feedforward trong transformer\n","max_seq_length = max_length  # Độ dài tối đa của chuỗi đầu vào\n","dropout = 0.1  # Tỷ lệ dropout\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=512):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_vocab_size=vocab_size, output_vocab_size=vocab_size, d_model=d_model, num_heads=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers):\n","        super(TransformerModel, self).__init__()\n","        self.embedding_encoder = nn.Embedding(input_vocab_size, d_model)\n","        self.embedding_decoder = nn.Embedding(output_vocab_size, d_model)\n","        self.pos_encoder = PositionalEncoding(d_model)\n","\n","        encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads)\n","        decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n","        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers)\n","\n","        self.fc = nn.Sequential(nn.Linear(d_model, dim_feedforward),\n","                                nn.Linear(dim_feedforward, output_vocab_size))\n","\n","    def forward(self, src, tgt):\n","        src = self.embedding_encoder(src)\n","        src = self.pos_encoder(src)\n","\n","        tgt = self.embedding_decoder(tgt)\n","        tgt = self.pos_encoder(tgt)\n","\n","        memory = self.transformer_encoder(src)\n","        output = self.transformer_decoder(tgt, memory)\n","\n","        output = self.fc(output)\n","        return output\n","\n","# Định nghĩa train loop\n","def train_epoch(model, dataloader, criterion, optimizer):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for input_xs, input_ys in dataloader:\n","        input_xs, input_ys = input_xs.squeeze(0), input_ys.squeeze(0)\n","        optimizer.zero_grad()\n","        outputs = model(input_xs, input_ys)\n","        loss = criterion(outputs, input_ys)\n","        loss.backward()\n","        optimizer.step()\n","        torch.save(model.state_dict(), '/kaggle/working/model_weights.pth')\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:19.238107Z","iopub.status.busy":"2024-03-11T09:07:19.237822Z","iopub.status.idle":"2024-03-11T09:07:19.427690Z","shell.execute_reply":"2024-03-11T09:07:19.426787Z","shell.execute_reply.started":"2024-03-11T09:07:19.238082Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([153, 1093]) torch.Size([153, 1093])\n"]}],"source":["#Gọi model, loss func và optimizer\n","\n","learning_rate = 0.1\n","\n","print(x_input_vectors[0].shape, y_input_vectors[0].shape)\n","\n","model = TransformerModel().to(device)\n","# model.load_state_dict(torch.load('/kaggle/input/weight/model_weights.pth'))\n","model = nn.DataParallel(model)\n","input_dataset = TensorDataset(x_input_vectors, y_input_vectors)\n","dataloader = DataLoader(input_dataset, shuffle=True, batch_size=1)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:19.429256Z","iopub.status.busy":"2024-03-11T09:07:19.428908Z","iopub.status.idle":"2024-03-11T09:07:19.435898Z","shell.execute_reply":"2024-03-11T09:07:19.434951Z","shell.execute_reply.started":"2024-03-11T09:07:19.429229Z"},"trusted":true},"outputs":[],"source":["#Train loop model\n","\n","num_epochs = 50\n","\n","for epoch in range(1, num_epochs + 1):\n","    train_loss = train_epoch(model, dataloader, criterion, optimizer)\n","    print(f'Epoch [{epoch}/{num_epochs}], Loss: {train_loss:.4f}')"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:07:19.437269Z","iopub.status.busy":"2024-03-11T09:07:19.437012Z","iopub.status.idle":"2024-03-11T09:07:32.458647Z","shell.execute_reply":"2024-03-11T09:07:32.457723Z","shell.execute_reply.started":"2024-03-11T09:07:19.437246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Đặt câu hỏi đến bác sĩ:  ho và sổ mũi\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/620528770.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(input_matrix, dtype=torch.long)\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([153, 1093])\n","giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác giác\n"]}],"source":["#Test model\n","\n","input_str = str(input(\"Đặt câu hỏi đến bác sĩ: \"))\n","ques_tokens = tokenizer(input_str)\n","ques_input = tokenize_ques_input_to_matrix(ques_tokens, len(vocab), max_length).squeeze()\n","print(ques_input.shape)\n","model.eval()\n","with torch.no_grad():\n","    output = model(ques_input, (ques_input != 0).long())\n","    print(vector_to_text(output, vocab))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
